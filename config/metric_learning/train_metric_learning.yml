model:
  _target_: ResNet50 # имя клаccа. Сам класс будет сконструирован в registry по этому имени
  mode: MetricLearning
  path: our_models/best.pth # Путь до расположения вашей локальной модели
  is_local: False # True если обучаете локально загруженную модель

args: # Различные аргументы для Catalyst
  expdir: src/metric_learning # Путь до нашего эксперимента, с файлом `__init__`, в котором импортируется Runner, и, опционально, регистрируются все дополнительные сущности: model, callback, criterion, etc
  logdir: logs # Путь в который будут сохранятся логи
  verbose: True # Нужно ли выводить на консоль информацию об обучении
  seed: 42 # сид обучения для PyTorch, Numpy, Python и Tensorflow
  deterministic: True # Нужно ли использовать deterministic CuDNN
  benchmark: True # Нужно ли использовать CuDNN benchmark

runner: # Параметры для инициализации Runner
   _target_: MertricLearningSupervisedRunner
   input_key: &model_input "features"
   output_key: &model_output "embeddings"
   target_key: &model_target "targets"
   loss_key: &model_loss "loss"

engine: # Параметры для distributed training и NVIDIA Apex
  _target_: DeviceEngine
  # device: cuda:0
loggers:
# Встроенные логеры каталиста
#(Возможные логеры: https://github.com/catalyst-team/catalyst/tree/master/catalyst/loggers)
  console:
    _target_: ConsoleLogger
  mlflow:
    _target_: MLflowLogger
    experiment: 'metric_learning'
  tensorboard:
    _target_: TensorboardLogger
    logdir: "./logs/ui"

stages: # Словарь всех стадий Catalyst, для обучения и/или инфера. Содержат ключевые слова с параметрами, которые применятся ко всем стейджам, так и сами имена стейджей
  stage:
    optimizer: # Параметры оптимизатора
      _target_: Adam
      lr: 0.001
    scheduler: # Подключение кастомного шедулера
      _key_value: False
      _target_: CustomScheduler
      delay_epochs: 5
      total_epochs: 10
      eta_min: 0.0001
    callbacks:
      iner:
        _target_: MLInerCallback
        incorrect_file: logs/csv/incorrect.csv
        uncoordinated_file: logs/csv/uncoordinated.csv
        threshold: 10.
      scheduler:
        _target_: SchedulerCallback
      # Подключение колбэков каталиста
      # (Возможные колбэки: https://github.com/catalyst-team/catalyst/tree/master/catalyst/callbacks)
      metric: # метрика
        _target_: CustomCMC
        embeddings_key: *model_output
        labels_key: *model_target
        is_query_key: "is_query"
        topk_args: [1]
        loaders: valid
      mlflow_logger: # Колбэк для логгирования фотографий, моделей, конфигов в mlflow
        _target_: MLFlowMetricLearningCallback
        logging_incorrect_image_number: 10 # Кол-во ошибочных фотографий и фотографий к которым модель отнесла ошибочные
        logging_uncoordinated_image_number: 10 # Кол-во фотографий которые не прошли по расстоянию
      tensordoard_logger:
        _target_: TensorboardMetricLearningCallback
        logging_incorrect_image_number: 10 # Кол-во ошибочных фотографий и фотографий к которым модель отнесла ошибочные
        logging_uncoordinated_image_number: 10 # Кол-во фотографий которые не прошли по расстоянию
      onnx_saver:
        _target_: OnnxSaveCallback
        out_dir: "./logs/onnx"
        checkpoint_names: ["best", "best_full"]
      torchscript_saver: # Конвертация в torchscript формат
        _target_: TorchscriptSaveCallback
        out_dir: "./logs/torchsript"
        checkpoint_names: ["best", "best_full"]
      # prunning: # Коллбэк для прунинга модели. Смотри документацию в Readme
      #   _target_: PruningCallback
      #   pruning_fn: random_unstructured # функция из модуля torch.nn.utils.prune или ваш на основе BasePruningMethod. Может быть строкой, например. " l1_unstructured ". Подробнее см. В документации по pytorch.
      #   prune_on_epoch_end: True # флаг для прунинга в конце стэйджа
      #   amount: 0.5 # количество параметров для обрезки. Если с плавающей точкой, должно быть от 0,0 до 1,0 и представляют собой часть параметров, подлежащих сокращению. Если int, он представляет собой абсолютное число параметров для обрезки.
      #   l_norm: 2
      quantization:
        _target_: QuantizationCallback
        logdir: "./logs" # Путь для сохранение модели после квантизации
      criterion:
        # Имеется возможность указать параметры scale и margin
        _target_: CustomTrainCriterion
        loss_type: arcface # Три 'loss_types' возможны: 'arcface', 'sphereface', 'cosface'
        num_classes: 102 # количество классов
        input_key: *model_output
        target_key: *model_target
        metric_key: *model_loss
        loaders: train

      optimizer: # Параметры для оптимизатора
        _target_: OptimizerCallback
        metric_key: *model_loss
      verbose:
        _target_: TqdmCallback
      saver: # Сохранение 3-х лучших моделей эксперимента
        _target_: CheckpointCallback
        logdir: "logs/checkpoints"
        save_n_best: 3

      # Подключение кастомных колбэков
      #(Возможные колбэки: ./src_multilabel/callbacks/)
    data:
      dataset_path: metric_learning_dataset # путь до датасета
      train_path: train # путь до папки с тренировочными фотографиями
      base_path: base # путь до папки с фотографиями галлереи
      val_path: val # путь до папки с фотографиями валидации(запроса/query)
      transform_path: config/augmentations/light.yml # Режим аугментаций данных (Возможны: light, medium, hard(./config/augmentations/))
      mode: Classic # Для использования lmdb датасета указать - LMDB
    loaders: &loaders
      batch_size: 1 # Размер батча для всех стейджей
      num_workers: 0 #для локальной поставить 0
    num_epochs: 25 # Количество эпох эксперимента
    valid_loader: valid
    main_metric: cmc01
    minimize_metric: False
