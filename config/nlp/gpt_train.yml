model:
  _target_: ruGPT3Models # имя клаccа. Сам класс будет сконструирован в registry по этому имени
  model_name: sberbank-ai/rugpt3small_based_on_gpt2

args: # Различные аргументы для Catalyst
  expdir: src/nlp # Путь до нашего эксперимента, с файлом `__init__`, в котором импортируется Runner, и, опционально, регистрируются все дополнительные сущности: model, callback, criterion, etc
  logdir: logs # Путь в который будут сохранятся логи
  verbose: True # Нужно ли выводить на консоль информацию об обучении
  seed: 42 # сид обучения для PyTorch, Numpy, Python и Tensorflow
  deterministic: True # Нужно ли использовать deterministic CuDNN
  benchmark: True # Нужно ли использовать CuDNN benchmark

runner: # Параметры для инициализации Runner
   _target_: NLPSupervisedRunner
   input_key: &model_input "text"
   output_key: &model_output "logits"
   target_key: &model_target "labels"
   loss_key: &model_loss "loss"

engine: # Параметры для distributed training и NVIDIA Apex
  _target_: DeviceEngine
  device: cpu

loggers:
# Встроенные логеры каталиста
#(Возможные логеры: https://github.com/catalyst-team/catalyst/tree/master/catalyst/loggers)
  console:
    _target_: ConsoleLogger

  mlflow:
    _target_: CustomMLflowLogger
    experiment: "gpt_check"


stages: # Словарь всех стадий Catalyst, для обучения и/или инфера. Содержат ключевые слова с параметрами, которые применятся ко всем стейджам, так и сами имена стейджей
  stage:

    optimizer: # Параметры оптимизатора
      _target_: AdamW
      lr: 0.00005

    callbacks:
      checkpoint:
        _target_: CheckpointCallback
        use_runner_logdir: True
        mode: model

      optimizer: # Параметры для оптимизатора
        _target_: OptimizerCallback
        metric_key: *model_loss

      # analyze:
      #   _target_: AnalyticsDistanceCallback
      #   analytics_data: "./nlp_dataset/napoleon_user_stories_clean.csv"
      #   similarity_file_path: "./logs/similarity.txt"
      #   cluster_file_path: "./logs/clusters.csv"

      # duplet:
      #   _target_: DupletMetricCallback
      #   duplets_file: ./nlp_dataset/dupl_stories_with_added_short.csv

      custom_mlflow:
        _target_: MLFlowNLPLoggingCallback
      verbose:
        _target_: TqdmCallback

    data: # Подключение данных и параметров обучения
      shuffle: True
      text: "./nlp_dataset/parse_user_story.txt"
    loaders: &loaders
      batch_size: 1 # Размер батча для всех стейджей
      num_workers: 0 #для локальной поставить 0
    num_epochs: 1 # Количество эпох эксперимента
    valid_loader: valid
    main_metric: loss
    minimize_metric: True
